{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c12e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = SparkSession.builder     .appName(\"StudentScoresDelta\")     .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")     .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc318e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_data = '''student_id,name,subject,score,grade\n",
    "1,Ankit,Math,85,A\n",
    "2,Divya,Science,92,A\n",
    "3,Rahul,English,78,B\n",
    "4,Sneha,Math,65,C\n",
    "5,Aryan,Science,55,D\n",
    "6,Isha,English,88,A\n",
    "7,Tanvi,Math,91,A\n",
    "8,Kunal,Science,72,B\n",
    "9,Megha,English,60,C\n",
    "10,Rohan,Math,40,F\n",
    "'''\n",
    "\n",
    "with open(\"/tmp/student_scores.csv\", \"w\") as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/tmp/student_scores.csv\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c10bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/student_scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS student_scores\")\n",
    "spark.sql(\"CREATE TABLE student_scores USING DELTA LOCATION '/tmp/delta/student_scores'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT name, subject, score FROM student_scores\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT subject, COUNT(*) as student_count FROM student_scores GROUP BY subject\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT subject, AVG(score) as avg_score FROM student_scores GROUP BY subject\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56425b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT name, score FROM student_scores WHERE score > 80\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e19d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT subject, name, score FROM (\n",
    "    SELECT *, RANK() OVER (PARTITION BY subject ORDER BY score DESC) as rnk \n",
    "    FROM student_scores\n",
    ") WHERE rnk = 1\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT grade, COUNT(*) as count FROM student_scores GROUP BY grade\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7a1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT name FROM student_scores WHERE grade = 'F'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT name, score FROM student_scores WHERE score BETWEEN 60 AND 90\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff482035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT subject, name, score, RANK() OVER (PARTITION BY subject ORDER BY score DESC) as rank \n",
    "FROM student_scores\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from delta.tables import DeltaTable\n",
    "deltaTable = DeltaTable.forPath(spark, \"/tmp/delta/student_scores\")\n",
    "deltaTable.update(condition=\"subject = 'English'\", set={\"score\": \"score + 5\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d962beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.delete(\"score < 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import when, col\n",
    "df = deltaTable.toDF()\n",
    "df = df.withColumn(\"pass_status\", when(col(\"score\") >= 50, \"PASS\").otherwise(\"FAIL\"))\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"student_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT subject, AVG(score) as avg_score FROM student_view GROUP BY subject\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540256f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/student_scores_v2\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS student_scores_v2\")\n",
    "spark.sql(\"CREATE TABLE student_scores_v2 USING DELTA LOCATION '/tmp/delta/student_scores_v2'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c75934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.write.mode(\"overwrite\").parquet(\"/tmp/output/student_scores_parquet\")\n",
    "df.write.mode(\"overwrite\").json(\"/tmp/output/student_scores_json\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

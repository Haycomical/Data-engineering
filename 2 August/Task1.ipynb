{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SNFEs_GvEk02"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BotCampus Intermediate Session\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n"
      ],
      "id": "SNFEs_GvEk02"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PtrxbK7Ek04",
        "outputId": "be8e2a01-a7f6-4d6c-b551-1643c414927c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Ananya|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [(\"Ananya\", \"Bangalore\", 24),\n",
        "        (\"Ravi\", \"Hyderabad\", 28),\n",
        "        (\"Kavya\", \"Delhi\", 22),\n",
        "        (\"Meena\", \"Chennai\", 25)]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "id": "_PtrxbK7Ek04"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kz_eSjjpEk07"
      },
      "outputs": [],
      "source": [
        "feedback = spark.sparkContext.parallelize([\n",
        "    \"Ravi from Bangalore loved the mobile app\",\n",
        "    \"Meena from Delhi reported poor response time\",\n",
        "    \"Ajay from Pune liked the delivery speed\",\n",
        "    \"Ananya from Hyderabad had an issue with UI\",\n",
        "    \"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "id": "kz_eSjjpEk07"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew_b0JhgEk07",
        "outputId": "041747d3-285d-45c4-f215-1b20b33dc10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 35\n"
          ]
        }
      ],
      "source": [
        "word_count = feedback.flatMap(lambda line: line.split()).count()\n",
        "print(\"Total words:\", word_count)"
      ],
      "id": "ew_b0JhgEk07"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POyYw2U7Ek08",
        "outputId": "0af09d37-b01c-46f9-a7fd-e214e55544ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 words: [('loved', 1), ('app', 1), ('poor', 1)]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "top_words = feedback.flatMap(lambda line: line.lower().split()) \\\n",
        "                    .filter(lambda word: word not in ['from', 'with', 'the', 'an']) \\\n",
        "                    .map(lambda word: (word, 1)) \\\n",
        "                    .reduceByKey(lambda a, b: a + b) \\\n",
        "                    .takeOrdered(3, key=lambda x: -x[1])\n",
        "print(\"Top 3 words:\", top_words)"
      ],
      "id": "POyYw2U7Ek08"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDw8hflXEk09",
        "outputId": "1c183721-e587-4ad4-b4ae-d10c1c7ddad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word count dictionary: {'loved': 1, 'app': 1, 'poor': 1, 'response': 1, 'liked': 1, 'speed': 1, 'ananya': 1, 'issue': 1, 'rohit': 1, 'mumbai': 1, 'positive': 1, 'feedback': 1, 'ravi': 1, 'bangalore': 1, 'mobile': 1, 'meena': 1, 'delhi': 1, 'reported': 1, 'time': 1, 'ajay': 1, 'pune': 1, 'delivery': 1, 'hyderabad': 1, 'had': 1, 'ui': 1, 'gave': 1}\n"
          ]
        }
      ],
      "source": [
        "word_dict = feedback.flatMap(lambda line: line.lower().split()) \\\n",
        "                    .filter(lambda word: word not in ['from', 'with', 'the', 'an']) \\\n",
        "                    .map(lambda word: (word, 1)) \\\n",
        "                    .reduceByKey(lambda a, b: a + b) \\\n",
        "                    .collectAsMap()\n",
        "print(\"Word count dictionary:\", word_dict)"
      ],
      "id": "TDw8hflXEk09"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "D3X9-2gDEk0-"
      },
      "outputs": [],
      "source": [
        "scores = [(\"Ravi\", \"Math\", 88),\n",
        "          (\"Ananya\", \"Science\", 92),\n",
        "          (\"Kavya\", \"English\", 79),\n",
        "          (\"Ravi\", \"English\", 67),\n",
        "          (\"Neha\", \"Math\", 94),\n",
        "          (\"Meena\", \"Science\", 85)]\n",
        "columns = [\"name\", \"subject\", \"score\"]\n",
        "df_scores = spark.createDataFrame(scores, columns)"
      ],
      "id": "D3X9-2gDEk0-"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vHJd1TB2Ek0_"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import when\n",
        "df_scores = df_scores.withColumn(\"grade\",\n",
        "             when(df_scores.score >= 90, \"A\")\n",
        "            .when((df_scores.score >= 80) & (df_scores.score < 90), \"B\")\n",
        "            .when((df_scores.score >= 70) & (df_scores.score < 80), \"C\")\n",
        "            .otherwise(\"D\"))"
      ],
      "id": "vHJd1TB2Ek0_"
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJtpnuXiFg-h",
        "outputId": "5b8d7114-4f21-469d-b233-aea8e06e5ec4"
      },
      "id": "xJtpnuXiFg-h",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+\n",
            "|  name|subject|score|grade|\n",
            "+------+-------+-----+-----+\n",
            "|  Ravi|   Math|   88|    B|\n",
            "|Ananya|Science|   92|    A|\n",
            "| Kavya|English|   79|    C|\n",
            "|  Ravi|English|   67|    D|\n",
            "|  Neha|   Math|   94|    A|\n",
            "| Meena|Science|   85|    B|\n",
            "+------+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cWFKkm7Ek0_",
        "outputId": "24a6bff6-087f-4446-a776-262fd77c7623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|subject|avg(score)|\n",
            "+-------+----------+\n",
            "|Science|      88.5|\n",
            "|   Math|      91.0|\n",
            "|English|      73.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_scores.groupBy(\"subject\").avg(\"score\").show()"
      ],
      "id": "8cWFKkm7Ek0_"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1SyIenwJEk0_"
      },
      "outputs": [],
      "source": [
        "df_scores = df_scores.withColumn(\"difficulty\",\n",
        "             when(df_scores.subject.isin(\"Math\", \"Science\"), \"Difficult\")\n",
        "             .otherwise(\"Easy\"))"
      ],
      "id": "1SyIenwJEk0_"
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75ZQLHahFpsV",
        "outputId": "45fff895-f346-4115-f97b-a2d9917ee260"
      },
      "id": "75ZQLHahFpsV",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+\n",
            "|  name|subject|score|grade|difficulty|\n",
            "+------+-------+-----+-----+----------+\n",
            "|  Ravi|   Math|   88|    B| Difficult|\n",
            "|Ananya|Science|   92|    A| Difficult|\n",
            "| Kavya|English|   79|    C|      Easy|\n",
            "|  Ravi|English|   67|    D|      Easy|\n",
            "|  Neha|   Math|   94|    A| Difficult|\n",
            "| Meena|Science|   85|    B| Difficult|\n",
            "+------+-------+-----+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "HbDOPedtEk1A"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank\n",
        "window_spec = Window.partitionBy(\"subject\").orderBy(df_scores.score.desc())\n",
        "df_scores = df_scores.withColumn(\"rank\", rank().over(window_spec))"
      ],
      "id": "HbDOPedtEk1A"
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICPqRy-3Ft7C",
        "outputId": "d67aa50c-1296-4afc-ee13-1b998e08de7c"
      },
      "id": "ICPqRy-3Ft7C",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+----+\n",
            "|  name|subject|score|grade|difficulty|rank|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "| Kavya|English|   79|    C|      Easy|   1|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|\n",
            "| Meena|Science|   85|    B| Difficult|   2|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI7OJobrEk1A",
        "outputId": "e4572f10-161e-4ca6-8227-7a2f2d897d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+----+--------------+\n",
            "|  name|subject|score|grade|difficulty|rank|formatted_name|\n",
            "+------+-------+-----+-----+----------+----+--------------+\n",
            "| Kavya|English|   79|    C|      Easy|   1|         KAVYA|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|          RAVI|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|          NEHA|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|          RAVI|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|        ANANYA|\n",
            "| Meena|Science|   85|    B| Difficult|   2|         MEENA|\n",
            "+------+-------+-----+-----+----------+----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def format_name(name):\n",
        "    return name.upper()\n",
        "\n",
        "format_name_udf = udf(format_name, StringType())\n",
        "df_scores = df_scores.withColumn(\"formatted_name\", format_name_udf(df_scores.name))\n",
        "df_scores.show()"
      ],
      "id": "yI7OJobrEk1A"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "students_data = {\n",
        "    \"id\": [1, 2, 3],\n",
        "    \"name\": [\"Amit\", \"Kavya\", \"Arjun\"],\n",
        "    \"department\": [\"IT\", \"HR\", \"Finance\"],\n",
        "    \"city\": [\"Bangalore\", \"Chennai\", \"Hyderabad\"],\n",
        "    \"salary\": [78000, 62000, 55000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(students_data)\n",
        "df.to_csv(\"students.csv\", index=False)"
      ],
      "metadata": {
        "id": "StL2DStHHRF5"
      },
      "id": "StL2DStHHRF5",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "employee_data = {\n",
        "    \"id\": 101,\n",
        "    \"name\": \"Sneha\",\n",
        "    \"address\": {\n",
        "        \"city\": \"Mumbai\",\n",
        "        \"pincode\": 400001\n",
        "    },\n",
        "    \"skills\": [\"Python\", \"Spark\", \"SQL\"]\n",
        "}\n",
        "\n",
        "with open(\"employee_nested.json\", \"w\") as f:\n",
        "    json.dump(employee_data, f, indent=4)"
      ],
      "metadata": {
        "id": "OZ11kfKTHRBb"
      },
      "id": "OZ11kfKTHRBb",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olom8JG1Ek1A",
        "outputId": "ddd1564b-e46a-4a3b-a945-634552bac182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "students_df = spark.read.option(\"header\", True).csv(\"students.csv\")\n",
        "students_df.printSchema()"
      ],
      "id": "olom8JG1Ek1A"
    },
    {
      "cell_type": "code",
      "source": [
        "students_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6NiA1ZVHQcX",
        "outputId": "c7c3a677-9d96-4a29-de37-ac43a400c8f9"
      },
      "id": "L6NiA1ZVHQcX",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+---------+------+\n",
            "| id| name|department|     city|salary|\n",
            "+---+-----+----------+---------+------+\n",
            "|  1| Amit|        IT|Bangalore| 78000|\n",
            "|  2|Kavya|        HR|  Chennai| 62000|\n",
            "|  3|Arjun|   Finance|Hyderabad| 55000|\n",
            "+---+-----+----------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD_u5W-xEk1B",
        "outputId": "f8824b41-8603-4c5d-a716-4534ccfe6129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- pincode: long (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- skills: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "employees_df = spark.read.option(\"multiline\", True).json(\"employee_nested.json\")\n",
        "employees_df.printSchema()"
      ],
      "id": "aD_u5W-xEk1B"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "oa0AtEdREk1B"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import explode, col\n",
        "flattened_df = employees_df.select(\n",
        "    \"id\",\n",
        "    \"name\",\n",
        "    col(\"address.city\").alias(\"city\"),\n",
        "    col(\"address.pincode\").alias(\"pincode\"),\n",
        "    explode(\"skills\").alias(\"skill\")\n",
        ")"
      ],
      "id": "oa0AtEdREk1B"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "o0mFuHhjEk1B"
      },
      "outputs": [],
      "source": [
        "students_df.write.parquet(\"/tmp/output/students\", mode=\"overwrite\")\n",
        "flattened_df.write.parquet(\"/tmp/output/employees\", mode=\"overwrite\")"
      ],
      "id": "o0mFuHhjEk1B"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "6Mb_E8j1Ek1B"
      },
      "outputs": [],
      "source": [
        "df_scores.createOrReplaceTempView(\"exam_scores\")\n"
      ],
      "id": "6Mb_E8j1Ek1B"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdC1WbnSEk1B",
        "outputId": "cb9d72b3-4e3c-4e0a-817c-d468bcff6af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+---------+\n",
            "|subject|  name|top_score|\n",
            "+-------+------+---------+\n",
            "|English| Kavya|       79|\n",
            "|English|  Ravi|       67|\n",
            "|   Math|  Neha|       94|\n",
            "|   Math|  Ravi|       88|\n",
            "|Science|Ananya|       92|\n",
            "|Science| Meena|       85|\n",
            "+-------+------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT subject, name, MAX(score) AS top_score\n",
        "FROM exam_scores\n",
        "GROUP BY subject, name\n",
        "ORDER BY subject, top_score DESC\n",
        "\"\"\").show()"
      ],
      "id": "jdC1WbnSEk1B"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqgOUNSBEk1C",
        "outputId": "8314ba6d-e4b0-4856-cc64-b15d326804a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|grade|count|\n",
            "+-----+-----+\n",
            "|    B|    2|\n",
            "|    C|    1|\n",
            "|    A|    2|\n",
            "|    D|    1|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT grade, COUNT(*) AS count FROM exam_scores GROUP BY grade\").show()"
      ],
      "id": "DqgOUNSBEk1C"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZr2PqTyEk1C",
        "outputId": "d2e93520-fd16-41cf-d837-a3e9854fc2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+\n",
            "|name|subjects|\n",
            "+----+--------+\n",
            "|Ravi|       2|\n",
            "+----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT name, COUNT(subject) AS subjects\n",
        "FROM exam_scores\n",
        "GROUP BY name\n",
        "HAVING subjects > 1\n",
        "\"\"\").show()"
      ],
      "id": "dZr2PqTyEk1C"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldhs6v_BEk1C",
        "outputId": "0d472ccd-52aa-4deb-8630-38112df232e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|subject|avg_score|\n",
            "+-------+---------+\n",
            "|Science|     88.5|\n",
            "|   Math|     91.0|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT subject, AVG(score) AS avg_score\n",
        "FROM exam_scores\n",
        "GROUP BY subject\n",
        "HAVING avg_score > 85\n",
        "\"\"\").show()"
      ],
      "id": "ldhs6v_BEk1C"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "pjVilxFyEk1D"
      },
      "outputs": [],
      "source": [
        "attendance = [(\"Ravi\", 18), (\"Ananya\", 21), (\"Kavya\", 20), (\"Neha\", 25), (\"Meena\", 19)]\n",
        "att_cols = [\"name\", \"days_present\"]\n",
        "df_att = spark.createDataFrame(attendance, att_cols)"
      ],
      "id": "pjVilxFyEk1D"
    },
    {
      "cell_type": "code",
      "source": [
        "df_att.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYJRZ1IrH94D",
        "outputId": "b4d63580-4ffc-41f9-913a-259da13325e5"
      },
      "id": "eYJRZ1IrH94D",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+\n",
            "|  name|days_present|\n",
            "+------+------------+\n",
            "|  Ravi|          18|\n",
            "|Ananya|          21|\n",
            "| Kavya|          20|\n",
            "|  Neha|          25|\n",
            "| Meena|          19|\n",
            "+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdV_IZxoEk1E",
        "outputId": "4f79f438-33ae-4861-b2f0-a5c2f7ff4d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+------------+--------------+\n",
            "|  name|subject|score|grade|days_present|adjusted_grade|\n",
            "+------+-------+-----+-----+------------+--------------+\n",
            "|Ananya|Science|   92|    A|          21|             A|\n",
            "|  Ravi|   Math|   88|    B|          18|             C|\n",
            "| Kavya|English|   79|    C|          20|             C|\n",
            "|  Ravi|English|   67|    D|          18|             D|\n",
            "|  Neha|   Math|   94|    A|          25|             A|\n",
            "| Meena|Science|   85|    B|          19|             C|\n",
            "+------+-------+-----+-----+------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "df_joined = df_scores.join(df_att, on=\"name\", how=\"left\")\n",
        "df_final = df_joined.withColumn(\"adjusted_grade\", expr(\"\"\"\n",
        "CASE\n",
        "  WHEN days_present < 20 AND grade = 'A' THEN 'B'\n",
        "  WHEN days_present < 20 AND grade = 'B' THEN 'C'\n",
        "  WHEN days_present < 20 AND grade = 'C' THEN 'D'\n",
        "  WHEN days_present < 20 AND grade = 'D' THEN 'D'\n",
        "  ELSE grade\n",
        "END\n",
        "\"\"\"))\n",
        "df_final.select(\"name\", \"subject\", \"score\", \"grade\", \"days_present\", \"adjusted_grade\").show()"
      ],
      "id": "KdV_IZxoEk1E"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Uh0CV2PxEk1G"
      },
      "outputs": [],
      "source": [
        "df_scores.write.partitionBy(\"subject\").parquet(\"/tmp/scores/\", mode=\"overwrite\")"
      ],
      "id": "Uh0CV2PxEk1G"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Gh48M-IgEk1G"
      },
      "outputs": [],
      "source": [
        "incremental = [(\"Meena\", \"Math\", 93)]\n",
        "df_inc = spark.createDataFrame(incremental, [\"name\", \"subject\", \"score\"])\n",
        "df_inc.write.mode(\"append\").partitionBy(\"subject\").parquet(\"/tmp/scores/\")"
      ],
      "id": "Gh48M-IgEk1G"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yE-B1OAEk1G",
        "outputId": "a33cd84c-4764-453f-ab3f-cd2b222418c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+\n",
            "| name|subject|score|\n",
            "+-----+-------+-----+\n",
            "|Meena|   Math|   93|\n",
            "+-----+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_inc.show()"
      ],
      "id": "8yE-B1OAEk1G"
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if7MMpchEk1H",
        "outputId": "b4e455dc-d54b-4b5e-e701-a676140f2438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----+----------+----+--------------+\n",
            "| name|score|grade|difficulty|rank|formatted_name|\n",
            "+-----+-----+-----+----------+----+--------------+\n",
            "| Neha|   94|    A| Difficult|   1|          NEHA|\n",
            "| Ravi|   88|    B| Difficult|   2|          RAVI|\n",
            "|Meena|   93| NULL|      NULL|NULL|          NULL|\n",
            "|Meena|   93| NULL|      NULL|NULL|          NULL|\n",
            "|Meena|   93| NULL|      NULL|NULL|          NULL|\n",
            "|Meena|   93| NULL|      NULL|NULL|          NULL|\n",
            "+-----+-----+-----+----------+----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_math = spark.read.parquet(\"/tmp/scores/subject=Math\")\n",
        "df_math.show()"
      ],
      "id": "if7MMpchEk1H"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "employee_data = {\n",
        "    \"emp_id\": [1, 2, 3],\n",
        "    \"name\": [\"Arjun\", \"Kavya\", \"Sneha\"],\n",
        "    \"dept\": [\"IT\", \"HR\", \"Finance\"],\n",
        "    \"salary\": [78000, 62000, 55000],\n",
        "    \"bonus\": [5000, None, 3000]  # None represents a missing value\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(employee_data)\n",
        "df.to_csv(\"emp_raw.csv\", index=False)"
      ],
      "metadata": {
        "id": "X4TZOx5yIb9y"
      },
      "id": "X4TZOx5yIb9y",
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssI0a47UEk1K",
        "outputId": "818ddf84-6011-4263-9aab-e7f9d1e85019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- emp_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- dept: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            " |-- bonus: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "etl_df = spark.read.option(\"header\", True).csv(\"emp_raw.csv\")\n",
        "etl_df.printSchema()"
      ],
      "id": "ssI0a47UEk1K"
    },
    {
      "cell_type": "code",
      "source": [
        "etl_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuZCSohIIwvc",
        "outputId": "70aa269e-edda-44af-aec1-2a7dfbcc00a7"
      },
      "id": "FuZCSohIIwvc",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+------+\n",
            "|emp_id| name|   dept|salary| bonus|\n",
            "+------+-----+-------+------+------+\n",
            "|     1|Arjun|     IT| 78000|5000.0|\n",
            "|     2|Kavya|     HR| 62000|  NULL|\n",
            "|     3|Sneha|Finance| 55000|3000.0|\n",
            "+------+-----+-------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "AmPJdIaOEk1L"
      },
      "outputs": [],
      "source": [
        "etl_df = etl_df.fillna({\"bonus\": 2000})"
      ],
      "id": "AmPJdIaOEk1L"
    },
    {
      "cell_type": "code",
      "source": [
        "etl_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HugyO2fEI7fi",
        "outputId": "68acf197-5fb7-4775-cad5-f9a53161710a"
      },
      "id": "HugyO2fEI7fi",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+------+\n",
            "|emp_id| name|   dept|salary| bonus|\n",
            "+------+-----+-------+------+------+\n",
            "|     1|Arjun|     IT| 78000|5000.0|\n",
            "|     2|Kavya|     HR| 62000|  2000|\n",
            "|     3|Sneha|Finance| 55000|3000.0|\n",
            "+------+-----+-------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "aFC1UJVsEk1L"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "etl_df = etl_df.withColumn(\"salary\", etl_df[\"salary\"].cast(IntegerType()))\n",
        "etl_df = etl_df.withColumn(\"bonus\", etl_df[\"bonus\"].cast(IntegerType()))"
      ],
      "id": "aFC1UJVsEk1L"
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "rG6_Xb23Ek1L"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "etl_df = etl_df.withColumn(\"total_ctc\", col(\"salary\") + col(\"bonus\"))"
      ],
      "id": "rG6_Xb23Ek1L"
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "RtAK9PFXEk1L"
      },
      "outputs": [],
      "source": [
        "etl_df = etl_df.filter(col(\"total_ctc\") > 60000)"
      ],
      "id": "RtAK9PFXEk1L"
    },
    {
      "cell_type": "code",
      "source": [
        "etl_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyadTswxJHuD",
        "outputId": "e4f19470-cce3-4eed-fad1-f23bd33db909"
      },
      "id": "hyadTswxJHuD",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+----+------+-----+---------+\n",
            "|emp_id| name|dept|salary|bonus|total_ctc|\n",
            "+------+-----+----+------+-----+---------+\n",
            "|     1|Arjun|  IT| 78000| 5000|    83000|\n",
            "|     2|Kavya|  HR| 62000| 2000|    64000|\n",
            "+------+-----+----+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "tsvCQ4ngEk1L"
      },
      "outputs": [],
      "source": [
        "etl_df.write.mode(\"overwrite\").parquet(\"/tmp/etl_output/parquet\")\n",
        "etl_df.write.mode(\"overwrite\").json(\"/tmp/etl_output/json\")"
      ],
      "id": "tsvCQ4ngEk1L"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}